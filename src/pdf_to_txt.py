import argparse
import os
import shutil
import logging
import re
from pathlib import Path
from datetime import datetime
import PyPDF2

def setup_logger(pdf_name):
    """Configura logger para registrar operaÃ§Ãµes"""
    log_dir = Path(__file__).parent.parent / "data" / "logs"
    log_dir.mkdir(parents=True, exist_ok=True)
    
    log_file = log_dir / f"{pdf_name.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    logging.basicConfig(
        filename=log_file,
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        force=True
    )
    return logging.getLogger(__name__)

def extract_text_from_pdf(pdf_path, encoding='utf-8'):
    """Extrai texto do PDF"""
    try:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page_num, page in enumerate(reader.pages):
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"
        return text if text.strip() else None
    except Exception as e:
        raise Exception(f"Erro ao extrair texto: {str(e)}")

def extract_main_info(text):
    """Extrai informaÃ§Ãµes principais do texto"""
    info = {
        'nome': None,
        'email': None,
        'telefone': None,
        'linkedin': None,
        'headline': None,
        'localizacao': None,
    }
    
    # Extrai email
    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    emails = re.findall(email_pattern, text)
    if emails:
        info['email'] = emails[0]
    
    # Extrai telefone
    phone_pattern = r'\+?55\s?\d{2}\s?\d{4,5}\s?\d{4}|\+?\d{10,}'
    phones = re.findall(phone_pattern, text)
    if phones:
        info['telefone'] = phones[0]
    
    # Extrai LinkedIn (versÃ£o melhorada para pegar o link completo)
    linkedin_pattern = r'(?:linkedin\.com/in/|www\.linkedin\.com/in/)([a-zA-Z0-9-]+)'
    linkedin = re.search(linkedin_pattern, text, re.IGNORECASE)
    if linkedin:
        info['linkedin'] = f"linkedin.com/in/{linkedin.group(1)}"
    else:
        # Tenta encontrar URLs de LinkedIn no texto
        url_pattern = r'(?:https?://)?(?:www\.)?linkedin\.com/in/[a-zA-Z0-9-]+'
        url_match = re.search(url_pattern, text, re.IGNORECASE)
        if url_match:
            url = url_match.group(0)
            # Remove https:// e www. se existirem
            url = re.sub(r'^(?:https?://)?(?:www\.)?', '', url)
            info['linkedin'] = url
    
    # Extrai nome e headline
    lines = text.split('\n')
    for i, line in enumerate(lines):
        line_clean = line.strip()
        
        # Procura por padrÃ£o de nome + headline (ex: "Alessandro Kulitch\nCoordenador de Engenharia...")
        if any(title in line for title in ['Coordenador', 'Engenheiro', 'Gerente', 'Analista', 'Professor', 'Consultor', 'Diretor', 'Especialista']):
            # Pega o prÃ³ximo padrÃ£o de cargo/headline
            if not info['headline']:
                info['headline'] = line_clean
            
            # Nome estÃ¡ poucas linhas antes
            if not info['nome']:
                for j in range(max(0, i-3), i):
                    candidate = lines[j].strip()
                    if candidate and len(candidate.split()) >= 2 and len(candidate) < 80:
                        if not any(char.isdigit() for char in candidate) and not any(kw in candidate for kw in ['Contato', 'Email', 'Phone', 'Mobile', 'LinkedIn']):
                            info['nome'] = candidate
                            break
    
    # Extrai localizaÃ§Ã£o
    city_pattern = r'(?:Curitiba|SÃ£o Paulo|Rio de Janeiro|Belo Horizonte|BrasÃ­lia|Salvador|Fortaleza|Manaus|Recife|Porto Alegre|GoiÃ¢nia|BelÃ©m|Guarulhos|Campinas|SÃ£o Bernardo do Campo|Santo AndrÃ©|Osasco|MauÃ¡|SÃ£o Caetano do Sul|Diadema|Sorocaba|JundiaÃ­|Piracicaba|RibeirÃ£o Preto|Araraquara|Bauru|Presidente Prudente|MarÃ­lia|Barueri|MaringÃ¡|Londrina|Cascavel|Foz do IguaÃ§u|Ponta Grossa|ParanaguÃ¡|Blumenau|Brusque|Joinville|FlorianÃ³polis|Lages|ChapecÃ³|CriciÃºma|ItajaÃ­|Pelotas|Rio Grande|Santa Maria|Novo Hamburgo|Gramado|Canoas|Caxias do Sul|ViamÃ£o|Alvorada|Sapucaia do Sul|Campo Bom|Cachoeirinha|Esteio|GravataÃ­|SÃ£o Leopoldo)\s*,\s*(?:ParanÃ¡|SÃ£o Paulo|Rio de Janeiro|Minas Gerais|Bahia|CearÃ¡|Amazonas|Pernambuco|Rio Grande do Sul|GoiÃ¡s|ParÃ¡|MaranhÃ£o|Santa Catarina|ParaÃ­ba|EspÃ­rito Santo|PiauÃ­|Rio Grande do Norte|Alagoas|Mato Grosso|Mato Grosso do Sul|Distrito Federal|Acre|AmapÃ¡|RondÃ´nia|Roraima|Tocantins)'
    loc_match = re.search(city_pattern, text, re.IGNORECASE)
    if loc_match:
        info['localizacao'] = loc_match.group(0)
    
    return info

def validate_content(text):
    """Valida se o PDF contÃ©m informaÃ§Ãµes relevantes"""
    keywords = ['linkedin', 'email', 'telefone', 'experiÃªncia', 'habilidades', 'name', 'phone', 'profissional', 'skills', 'enginee', 'coordena', 'cargo']
    found_keywords = [kw for kw in keywords if kw.lower() in text.lower()]
    return len(found_keywords) > 0, found_keywords

def extract_relevant_experience(text):
    """Extrai apenas as experiÃªncias profissionais (atÃ© 2 primeiras)"""
    # Tenta encontrar a seÃ§Ã£o de experiÃªncia
    exp_section = re.search(r'ExperiÃªncia(.*?)(?:FormaÃ§Ã£o|EducaÃ§Ã£o|Skills|CompetÃªncias|$)', text, re.DOTALL | re.IGNORECASE)
    
    if exp_section:
        exp_text = exp_section.group(1)
        # Limita para evitar muita informaÃ§Ã£o
        lines = exp_text.split('\n')
        # Retorna atÃ© 30 linhas (aproximadamente 2 experiÃªncias)
        relevant = '\n'.join(lines[:30])
        return relevant.strip()
    return ""

def format_output(pdf_name, info, full_text):
    """Formata as informaÃ§Ãµes extraÃ­das para saÃ­da limpa e estruturada"""
    
    # Extrai seÃ§Ã£o de experiÃªncias
    experience_section = extract_relevant_experience(full_text)
    
    output = f"""â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ RESUMO - INFORMAÃ‡Ã•ES DO CANDIDATO
â•‘ {pdf_name}
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ DADOS PESSOAIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Nome: {info['nome'] or 'NÃ£o identificado'}
Email: {info['email'] or 'NÃ£o identificado'}
Telefone: {info['telefone'] or 'NÃ£o identificado'}
LinkedIn: {info['linkedin'] or 'NÃ£o identificado'}
LocalizaÃ§Ã£o: {info['localizacao'] or 'NÃ£o identificado'}

ğŸ’¼ HEADLINE PROFISSIONAL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{info['headline'] or 'NÃ£o identificado'}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“„ EXPERIÃŠNCIA PROFISSIONAL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

{experience_section if experience_section else 'NÃ£o encontrado'}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ CONTEÃšDO COMPLETO DO CURRÃCULO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

{full_text}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Processado em: {datetime.now().strftime('%d/%m/%Y Ã s %H:%M:%S')}
"""
    
    return output

def process_pdf(input_path, output_dir, encoding='utf-8'):
    """Processa um PDF: extrai texto, valida e organiza arquivos"""
    pdf_path = Path(input_path)
    
    # Valida se arquivo existe
    if not pdf_path.exists():
        print(f"âŒ Erro: Arquivo nÃ£o encontrado: {input_path}")
        return 1
    
    logger = setup_logger(pdf_path)
    
    logger.info(f"{'='*60}")
    logger.info(f"Iniciando processamento: {pdf_path.name}")
    logger.info(f"Caminho: {pdf_path.absolute()}")
    logger.info(f"Encoding: {encoding}")
    
    try:
        # Extrai texto
        print(f"\nğŸ“– Lendo PDF: {pdf_path.name}")
        text = extract_text_from_pdf(pdf_path, encoding)
        
        if not text:
            print(f"âš ï¸  PDF vazio ou sem texto extraÃ­do")
            logger.warning("PDF vazio ou sem texto extraÃ­do")
            return 1
        
        print(f"âœ“ Texto extraÃ­do ({len(text)} caracteres)")
        logger.info(f"Texto extraÃ­do com sucesso ({len(text)} caracteres)")
        
        # Valida conteÃºdo
        print(f"ğŸ” Validando conteÃºdo...")
        is_valid, keywords_found = validate_content(text)
        
        if not is_valid:
            print(f"âš ï¸  PDF nÃ£o contÃ©m informaÃ§Ãµes relevantes")
            logger.warning(f"PDF nÃ£o contÃ©m informaÃ§Ãµes relevantes. Nenhuma palavra-chave encontrada.")
            return 1
        
        print(f"âœ“ Palavras-chave encontradas: {', '.join(keywords_found)}")
        logger.info(f"ValidaÃ§Ã£o bem-sucedida. Palavras-chave: {keywords_found}")
        
        # Extrai informaÃ§Ãµes principais
        print(f"ğŸ“Š Extraindo informaÃ§Ãµes principais...")
        info = extract_main_info(text)
        logger.info(f"InformaÃ§Ãµes extraÃ­das: Nome={info['nome']}, Email={info['email']}, LinkedIn={info['linkedin']}")
        
        # Formata saÃ­da
        formatted_output = format_output(pdf_path.stem, info, text)
        
        # Salva arquivo TXT
        print(f"ğŸ’¾ Salvando arquivo TXT...")
        output_path = Path(output_dir) / f"{pdf_path.stem}.txt"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding=encoding) as f:
            f.write(formatted_output)
        
        print(f"âœ“ TXT gerado: {output_path.name}")
        logger.info(f"TXT gerado com sucesso: {output_path.name}")
        logger.info(f"Caminho de saÃ­da: {output_path.absolute()}")
        logger.info(f"{'='*60}\n")
        
        return 0
        
    except Exception as e:
        print(f"âŒ Erro: {str(e)}")
        logger.error(f"Erro no processamento: {str(e)}")
        logger.info(f"{'='*60}\n")
        return 1

def main():
    parser = argparse.ArgumentParser(
        description='Extrai informaÃ§Ãµes de PDF e gera arquivo TXT estruturado',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python pdf_to_txt.py --input data/raw_pdfs/arquivo.pdf --output data/txt
  python pdf_to_txt.py --input data/raw_pdfs/arquivo.pdf --output data/txt --encoding utf-8
        """
    )
    parser.add_argument('--input', required=True, help='Caminho do PDF de entrada')
    parser.add_argument('--output', required=True, help='DiretÃ³rio de saÃ­da para TXT')
    parser.add_argument('--encoding', default='utf-8', help='CodificaÃ§Ã£o do arquivo (padrÃ£o: utf-8)')
    
    args = parser.parse_args()
    
    status = process_pdf(args.input, args.output, args.encoding)
    exit(status)

if __name__ == "__main__":
    main()