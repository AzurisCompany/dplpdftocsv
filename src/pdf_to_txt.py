import argparse
import os
import shutil
import logging
import re
from pathlib import Path
from datetime import datetime
import PyPDF2

def setup_logger(pdf_name):
    """Configura logger para registrar operaÃ§Ãµes"""
    log_dir = Path(__file__).parent.parent / "data" / "logs"
    log_dir.mkdir(parents=True, exist_ok=True)
    
    log_file = log_dir / f"{pdf_name.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    
    logging.basicConfig(
        filename=log_file,
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        force=True
    )
    return logging.getLogger(__name__)

def extract_text_from_pdf(pdf_path, encoding='utf-8'):
    """Extrai texto do PDF"""
    try:
        with open(pdf_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            text = ""
            for page_num, page in enumerate(reader.pages):
                extracted = page.extract_text()
                if extracted:
                    text += extracted + "\n"
        return text if text.strip() else None
    except Exception as e:
        raise Exception(f"Erro ao extrair texto: {str(e)}")

def extract_main_info(text):
    """Extrai informaÃ§Ãµes principais do texto"""
    info = {
        'nome': None,
        'email': None,
        'telefone': None,
        'linkedin': None,
        'headline': None,
        'localizacao': None,
    }
    
    # Divide o texto em linhas uma Ãºnica vez
    lines = text.split('\n')
    
    # Extrai email
    email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
    emails = re.findall(email_pattern, text)
    if emails:
        info['email'] = emails[0]
    
    # Extrai telefone
    phone_pattern = r'\+?55\s?\d{2}\s?\d{4,5}\s?\d{4}|\+?\d{10,}'
    phones = re.findall(phone_pattern, text)
    if phones:
        info['telefone'] = phones[0]
    
    # Extrai LinkedIn - Busca no texto original com quebras de linha
    linkedin_with_break = re.search(r'linkedin\.com/in/([a-zA-Z0-9-]+)\s*\n\s*([a-zA-Z0-9-]+)', text, re.IGNORECASE)
    if linkedin_with_break:
        username = linkedin_with_break.group(1) + linkedin_with_break.group(2)
        info['linkedin'] = f"linkedin.com/in/{username}"
    else:
        text_normalized = text.replace('\n', ' ')
        linkedin_url_pattern = r'(?:https?://)?(?:www\.)?linkedin\.com/in/([a-zA-Z0-9-]+)'
        linkedin_match = re.search(linkedin_url_pattern, text_normalized, re.IGNORECASE)
        
        if linkedin_match:
            username = linkedin_match.group(1).strip()
            info['linkedin'] = f"linkedin.com/in/{username}"
    
    # Extrai NOME - Usa o username do LinkedIn como referÃªncia
    if info['linkedin']:
        username = info['linkedin'].replace('linkedin.com/in/', '').lower()
        username_parts = username.split('-')
        
        if len(username_parts) >= 2:
            first_name = username_parts[0].capitalize()
            last_name = username_parts[1].capitalize()
            
            # Procura por esse padrÃ£o no texto
            name_pattern = rf'{first_name}\s+{last_name}'
            name_match = re.search(name_pattern, text, re.IGNORECASE)
            
            if name_match:
                info['nome'] = name_match.group(0)
            else:
                # Fallback: procura por qualquer combinaÃ§Ã£o
                name_pattern = rf'{first_name}.*?{last_name}'
                name_match = re.search(name_pattern, text, re.IGNORECASE | re.DOTALL)
                if name_match:
                    found_name = name_match.group(0).replace('\n', ' ').strip()
                    if len(found_name) < 80:
                        info['nome'] = found_name
    
    # Se nÃ£o conseguiu pelo LinkedIn, tenta buscar manualmente
    if not info['nome']:
        for i, line in enumerate(lines):
            line_clean = line.strip()
            
            # Procura por primeira linha com 2-4 palavras capitalizadas apÃ³s "Languages"
            if i > 0 and 'Languages' in lines[i-1]:
                words = line_clean.split()
                if 2 <= len(words) <= 4 and line_clean and '(' not in line_clean:
                    is_name = all(w[0].isupper() and w.replace('-', '').isalpha() for w in words if w)
                    if is_name:
                        info['nome'] = line_clean
                        break
    
    # Extrai HEADLINE - Procura por linhas com pipes (|) que indicam mÃºltiplos cargos
    # O headline pode ocupar mÃºltiplas linhas
    for i, line in enumerate(lines):
        if '|' in line or any(title in line for title in ['Coordenador', 'Engenheiro', 'Gerente', 'Analista', 'Professor', 'Consultor', 'Diretor', 'Especialista', 'Mestre']):
            if not info['headline']:
                # Junta linhas consecutivas que fazem parte do headline
                headline_lines = [line.strip()]
                
                # Verifica prÃ³ximas linhas se continuam o headline
                j = i + 1
                while j < len(lines):
                    next_line = lines[j].strip()
                    
                    # Para se encontrar palavras-chave que indicam fim do headline
                    if next_line and not ('|' in next_line or any(title in next_line for title in ['Coordenador', 'Engenheiro', 'Gerente', 'Analista', 'Professor', 'Consultor', 'Diretor', 'Especialista', 'Mestre', 'Automotiva', 'ElÃ©tricos', 'HÃ­bridos'])):
                        break
                    
                    # Se linha estÃ¡ vazia ou tem "Curitiba" (localizaÃ§Ã£o), para
                    if not next_line or 'Curitiba' in next_line or 'Brasil' in next_line or 'SÃ£o Paulo' in next_line:
                        break
                    
                    headline_lines.append(next_line)
                    j += 1
                
                # Junta as linhas do headline
                info['headline'] = ' '.join(headline_lines)
                
                # Remove mÃºltiplos espaÃ§os
                info['headline'] = re.sub(r'\s+', ' ', info['headline']).strip()
                break
    
    # Extrai localizaÃ§Ã£o
    city_pattern = r'(?:Curitiba|SÃ£o Paulo|Rio de Janeiro|Belo Horizonte|BrasÃ­lia|Salvador|Fortaleza|Manaus|Recife|Porto Alegre|GoiÃ¢nia|BelÃ©m|Guarulhos|Campinas|SÃ£o Bernardo do Campo|Santo AndrÃ©|Osasco|MauÃ¡|SÃ£o Caetano do Sul|Diadema|Sorocaba|JundiaÃ­|Piracicaba|RibeirÃ£o Preto|Araraquara|Bauru|Presidente Prudente|MarÃ­lia|Barueri|MaringÃ¡|Londrina|Cascavel|Foz do IguaÃ§u|Ponta Grossa|ParanaguÃ¡|Blumenau|Brusque|Joinville|FlorianÃ³polis|Lages|ChapecÃ³|CriciÃºma|ItajaÃ­|Pelotas|Rio Grande|Santa Maria|Novo Hamburgo|Gramado|Canoas|Caxias do Sul|ViamÃ£o|Alvorada|Sapucaia do Sul|Campo Bom|Cachoeirinha|Esteio|GravataÃ­|SÃ£o Leopoldo)\s*,\s*(?:ParanÃ¡|SÃ£o Paulo|Rio de Janeiro|Minas Gerais|Bahia|CearÃ¡|Amazonas|Pernambuco|Rio Grande do Sul|GoiÃ¡s|ParÃ¡|MaranhÃ£o|Santa Catarina|ParaÃ­ba|EspÃ­rito Santo|PiauÃ­|Rio Grande do Norte|Alagoas|Mato Grosso|Mato Grosso do Sul|Distrito Federal|Acre|AmapÃ¡|RondÃ´nia|Roraima|Tocantins)'
    loc_match = re.search(city_pattern, text, re.IGNORECASE)
    if loc_match:
        info['localizacao'] = loc_match.group(0)
    
    return info

def validate_content(text):
    """Valida se o PDF contÃ©m informaÃ§Ãµes relevantes"""
    keywords = ['linkedin', 'email', 'telefone', 'experiÃªncia', 'habilidades', 'name', 'phone', 'profissional', 'skills', 'enginee', 'coordena', 'cargo']
    found_keywords = [kw for kw in keywords if kw.lower() in text.lower()]
    return len(found_keywords) > 0, found_keywords

def extract_relevant_experience(text):
    """Extrai o resumo profissional com quebra de linha a cada 12 palavras"""
    # Tenta encontrar a seÃ§Ã£o "Resumo"
    resumo_section = re.search(r'Resumo\s*(.*?)(?:\nExperiÃªncia|\nFormaÃ§Ã£o|\nEducaÃ§Ã£o|\nSkills|\nCompetÃªncias|$)', text, re.DOTALL | re.IGNORECASE)
    
    if resumo_section:
        resumo_text = resumo_section.group(1).strip()
        
        # Divide por parÃ¡grafos (duas ou mais quebras de linha)
        paragraphs = re.split(r'\n\s*\n+', resumo_text)
        
        if paragraphs:
            # Processa cada parÃ¡grafo
            processed_paragraphs = []
            for para in paragraphs:
                para = para.strip()
                if para:  # Se parÃ¡grafo nÃ£o estÃ¡ vazio
                    # Remove quebras de linha internas e normaliza espaÃ§os
                    para = re.sub(r'\n+', ' ', para)
                    para = re.sub(r'\s+', ' ', para).strip()
                    
                    # Adiciona quebra de linha a cada 12 palavras
                    words = para.split()
                    lines = []
                    for i in range(0, len(words), 12):
                        lines.append(' '.join(words[i:i+12]))
                    
                    processed_paragraphs.append('\n'.join(lines))
            
            # Junta parÃ¡grafos com quebra de linha dupla
            return '\n\n'.join(processed_paragraphs)
    
    return ""

def format_output(pdf_name, info, full_text):
    """Formata as informaÃ§Ãµes extraÃ­das para saÃ­da limpa e estruturada"""
    
    # Extrai seÃ§Ã£o de experiÃªncias
    experience_section = extract_relevant_experience(full_text)
    
    output = f"""â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ RESUMO - INFORMAÃ‡Ã•ES DO CANDIDATO
â•‘ {pdf_name}
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ DADOS PESSOAIS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Nome: {info['nome'] or 'NÃ£o identificado'}
Email: {info['email'] or 'NÃ£o identificado'}
Telefone: {info['telefone'] or 'NÃ£o identificado'}
LinkedIn: {info['linkedin'] or 'NÃ£o identificado'}
Cargo: {info['headline'] or 'NÃ£o identificado'}
LocalizaÃ§Ã£o: {info['localizacao'] or 'NÃ£o identificado'}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“„ EXPERIÃŠNCIA PROFISSIONAL
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

{experience_section if experience_section else 'NÃ£o encontrado'}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ CONTEÃšDO COMPLETO DO CURRÃCULO
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

{full_text}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Processado em: {datetime.now().strftime('%d/%m/%Y Ã s %H:%M:%S')}
"""
    
    return output

def process_pdf(input_path, output_dir, encoding='utf-8'):
    """Processa um PDF: extrai texto, valida e organiza arquivos"""
    pdf_path = Path(input_path)
    
    # Valida se arquivo existe
    if not pdf_path.exists():
        print(f"âŒ Erro: Arquivo nÃ£o encontrado: {input_path}")
        return 1
    
    logger = setup_logger(pdf_path)
    
    logger.info(f"{'='*60}")
    logger.info(f"Iniciando processamento: {pdf_path.name}")
    logger.info(f"Caminho: {pdf_path.absolute()}")
    logger.info(f"Encoding: {encoding}")
    
    try:
        # Extrai texto
        print(f"\nğŸ“– Lendo PDF: {pdf_path.name}")
        text = extract_text_from_pdf(pdf_path, encoding)
        
        if not text:
            print(f"âš ï¸  PDF vazio ou sem texto extraÃ­do")
            logger.warning("PDF vazio ou sem texto extraÃ­do")
            return 1
        
        print(f"âœ“ Texto extraÃ­do ({len(text)} caracteres)")
        logger.info(f"Texto extraÃ­do com sucesso ({len(text)} caracteres)")
        
        # Valida conteÃºdo
        print(f"ğŸ” Validando conteÃºdo...")
        is_valid, keywords_found = validate_content(text)
        
        if not is_valid:
            print(f"âš ï¸  PDF nÃ£o contÃ©m informaÃ§Ãµes relevantes")
            logger.warning(f"PDF nÃ£o contÃ©m informaÃ§Ãµes relevantes. Nenhuma palavra-chave encontrada.")
            return 1
        
        print(f"âœ“ Palavras-chave encontradas: {', '.join(keywords_found)}")
        logger.info(f"ValidaÃ§Ã£o bem-sucedida. Palavras-chave: {keywords_found}")
        
        # Extrai informaÃ§Ãµes principais
        print(f"ğŸ“Š Extraindo informaÃ§Ãµes principais...")
        info = extract_main_info(text)
        logger.info(f"InformaÃ§Ãµes extraÃ­das: Nome={info['nome']}, Email={info['email']}, LinkedIn={info['linkedin']}")
        
        # Formata saÃ­da
        formatted_output = format_output(pdf_path.stem, info, text)
        
        # Salva arquivo TXT
        print(f"ğŸ’¾ Salvando arquivo TXT...")
        output_path = Path(output_dir) / f"{pdf_path.stem}.txt"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding=encoding) as f:
            f.write(formatted_output)
        
        print(f"âœ“ TXT gerado: {output_path.name}")
        logger.info(f"TXT gerado com sucesso: {output_path.name}")
        logger.info(f"Caminho de saÃ­da: {output_path.absolute()}")
        logger.info(f"{'='*60}\n")
        
        return 0
        
    except Exception as e:
        print(f"âŒ Erro: {str(e)}")
        logger.error(f"Erro no processamento: {str(e)}")
        logger.info(f"{'='*60}\n")
        return 1

def main():
    parser = argparse.ArgumentParser(
        description='Extrai informaÃ§Ãµes de PDF e gera arquivo TXT estruturado',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python pdf_to_txt.py --input data/raw_pdfs/arquivo.pdf --output data/txt
  python pdf_to_txt.py --input data/raw_pdfs/arquivo.pdf --output data/txt --encoding utf-8
        """
    )
    parser.add_argument('--input', required=True, help='Caminho do PDF de entrada')
    parser.add_argument('--output', required=True, help='DiretÃ³rio de saÃ­da para TXT')
    parser.add_argument('--encoding', default='utf-8', help='CodificaÃ§Ã£o do arquivo (padrÃ£o: utf-8)')
    
    args = parser.parse_args()
    
    status = process_pdf(args.input, args.output, args.encoding)
    exit(status)

if __name__ == "__main__":
    main()